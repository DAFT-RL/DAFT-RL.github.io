<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Fan Feng</a>,</span>
                <span class="author-block">
                  <a href="https://saramagliacane.github.io/" target="_blank">Sara Magliacane</a></span>
                  
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      City University of Hong Kong, University of Amsterdam, MIT-IBM Watson AI Lab<br><strong>NeurIPS 2023</strong></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/pdf?id=bsNslV3Ahe" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                     <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2307.09205" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                    <!-- Poster PDF link -->
                    <span class="link-block">
                      <a href="https://daft-rl.github.io" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://daft-rl.github.io" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

               
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In many reinforcement learning tasks, the agent has to learn to interact with many objects of different types and generalize to unseen combinations and numbers of objects. Often a task is a composition of previously learned tasks (e.g. block stacking). These are examples of compositional generalization, in which we compose object-centric representations to solve complex tasks. Recent works have shown the benefits of object-factored representations and hierarchical abstractions for improving sample efficiency in these settings. On the other hand, these methods do not fully exploit the benefits of factorization in terms of object attributes. In this paper, we address this opportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL) framework. In DAFT-RL, we leverage object-centric representation learning to extract objects from visual inputs. We learn to classify them in classes and infer their latent parameters. For each class of object, we learn a class template graph that describes how the dynamics and reward of an object of this class factorize according to its attributes. We also learn an interaction pattern graph that describes how objects of different classes interact with each other at the attribute level. Through these graphs and a dynamic interaction graph that models the interactions between objects, we can learn a policy that can then be directly applied in a new environment by just estimating the interactions and latent parameters. We evaluate DAFT-RL in three benchmark datasets and show our framework outperforms the state-of-the-art in generalizing across unseen objects with varying attributes and latent parameters, as well as in the composition of previously learned tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Dynamic, attributed-factored MDPs (DAFT-MDPs)</h2>
        <div class="content has-text-justified">
          <p>
            </p><div class="columns  is-four-fifths is-centered has-text-centered">
              <div class="column">
                <img src="static/images/graphical_rep.png" alt="Graphical Representation" style="max-width: 100%; height: auto;">

        
                <div class="column">
                  <div class="content has-text-justified">
                    <p>
                      <b>Figure 1</b> The graphical representation of DAFT-MDP. The colors denote the attributes for an object or a class, the red dashed lines denote edges that can be switched on or off at different timesteps.
                    </p>
                  </div>
                </div>

              </div>

            </div>
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Learning Framework</h2>
        <div class="content has-text-justified">
          <p>
            </p><div class="columns  is-four-fifths is-centered has-text-centered">
              <div class="column">
                <img src="static/images/pipeline.png" alt="Learning Framework" style="max-width: 100%; height: auto;">

              
               

              </div>

            </div>
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Experimental Results</h2>
        <h3 class="title is-4">Main Results</h3>
        <div class="content has-text-justified">
          <p>
            </p><div class="columns  is-four-fifths is-centered has-text-centered">
              <div class="column">
                <img src="static/images/tab1.png" alt="Experiment" style="max-width: 100%; height: auto;">


                <div class="column">
                  <div class="content has-text-justified">
                    <p>
                      <b>Table 1</b> Average success rate over 3 random seeds for Push & Switch compositional generalization in terms of combination of skills (S), changing number of objects (O), and changing latent parameters (L) with respect to training. The numbers in bold highlight the top-performing method.
                    </p>
                  </div>
                </div>

                <br>
                <br>

                <div class="column">
                  <img src="static/images/tab2.png" alt="Experiment" style="max-width: 100%; height: auto;">

                

                  <div class="column">
                    <div class="content has-text-justified">
                      <p>
                        <b>Table 2</b> Average success rate over 3 random seeds for Spriteworld with unseen object numbers, color and shape combinations. The numbers in bold highlight the top-performing method.
                      </p>
                    </div>
                  </div>

                  <br>
                  <br>

                  <div class="column">
                    <img src="static/images/tab3.png" alt="Experiment" style="max-width: 100%; height: auto;">


                    <div class="column">
                      <div class="content has-text-justified">
                        <p>
                          <b>Table 3</b> Average success rate over 3 random seeds for Block-stacking with unseen object numbers
                          0.4 and mass combinations. The numbers in bold highlight the top-performing method.
                        </p>
                      </div>
                    </div>

                    <br>
                    <br>

                    <div class="column">
                      <img src="static/images/fig2.png" alt="Experiment" style="max-width: 100%; height: auto;">

                    
                      <div class="column">
                        <div class="content has-text-justified">
                          <p>
                            <b>Figure 2</b> 
                            A. The smoothed learning curve for 2-Push + 2-Switch (L+S) with different friction coefficients for each object (for clarity, we show only the top three methods in terms of the success rate); B. The smoothed learning curve for the object comparison task in Spriteworld with unseen object numbers, combinations of colors and shapes (for clarity, we show only the top three methods in terms of the success rate); C. Success rate versus number of blocks in the stacking task, where each block has distinct mass.
                          </p>
                        </div>
                      </div>
                    </div>

                  </div>
                <p></p>
              </div>
            </div>
          </div>
        </div>
        <h3 class="title is-4">Ablation Studies</h3>
        <div class="column">
          <img src="static/images/ab1.png" alt="Experiment" style="max-width: 50%; height: auto;">
          <div class="column">
            <div class="content has-text-centered">
              <p>
                <b>Figure 3</b> 3-Push+3-Switch task.</p>
            </div>
          </div>
        </div>

        <div class="column">
          <img src="static/images/ab2.png" alt="Experiment" style="max-width: 100%; height: auto;">
          <div class="column">
            <div class="content has-text-justified">
              <p>
                <b>Figure 4</b> Quality of learned graphs w.r.t. the number of samples for 3-Push + 3-Switch (L+O+S). We plot the success rate of the RL task, the 
                <span id="MJXc-Node-125" class="mjx-msubsup">
                  <span class="mjx-base" style="margin-right:-0.188cm;">
                    <span id="MJXc-Node-126" class="mjx-mi">
                      <span class="mjx-char MJXc-TeX-math-BI" style="padding-top: 0.467em; padding-bottom: 0.313em; padding-right: 0em;">R</span>
                    </span>
                  </span>
                  <span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.041em; padding-right: 0.071em;">
                    <span id="MJXc-Node-127" class="mjx-texatom" style="">
                        <span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.003em; padding-bottom: 0.313em;">2</span>
                    </span>
                  </span>
                </span>
              </span>
                coefficient for learned representation vs the true latent parameters, and normalized Structured Hamming Distance (nSHD) between the learned graph and true graph under different number of training samples (measured as a ratio with the ones in the main paper) for (a) data collected by random policy, and (b) data collected by pre-trained policy.</p>
            </div>
          </div>
        </div>
        
      </div></div></div></section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
        feng2023learning,
        title={Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning},
        author={Fan Feng and Sara Magliacane},
        booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
        year={2023},
        url={https://openreview.net/forum?id=bsNslV3Ahe}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
